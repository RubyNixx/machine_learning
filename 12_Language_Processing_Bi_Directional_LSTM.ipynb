{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IAQT7F2zKuo2"},"source":["## Bi-Directional LSTMs\n","\n","Reference [Jon Krohn](https://github.com/the-deep-learners/TensorFlow-LiveLessons/blob/master/notebooks/bidirectional_lstm.ipynb)\n","\n","In this model, we classify sentiment of movie review from IMDB using a di-directional LSTM"]},{"cell_type":"code","metadata":{"id":"BYL61o-NJNwa","executionInfo":{"status":"ok","timestamp":1721384673501,"user_tz":-60,"elapsed":1643,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["\n","import keras\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n","from tensorflow.keras.layers import Bidirectional # note this dependency\n","from keras.callbacks import ModelCheckpoint\n","import os\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h7csQx-SM4tO"},"source":["Load Data"]},{"cell_type":"code","metadata":{"id":"FOUD3f90VaIO","executionInfo":{"status":"ok","timestamp":1721384678996,"user_tz":-60,"elapsed":6,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["# vector-space embedding\n","n_dim = 64\n","n_unique_words = 10000\n","max_review_length = 200\n","# this can be a bit longer, we are reading our reviews in both directions\n","# gradients disappear from both ends of the sequence\n","pad_type = trunc_type = 'pre'\n","drop_embed = 0.2"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"jogUHkucLP37","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf196b9b-cd67-41fe-f05d-39792197cfba","executionInfo":{"status":"ok","timestamp":1721384688029,"user_tz":-60,"elapsed":6138,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"7hTxZ8vuM2Qb"},"source":["Preprocess the data"]},{"cell_type":"code","metadata":{"id":"SN8anY0mLP-9","executionInfo":{"status":"ok","timestamp":1721384694965,"user_tz":-60,"elapsed":1347,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n","x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kAlFGr9LMC2x"},"source":["Set Hyperparameters"]},{"cell_type":"code","metadata":{"id":"XBnVOfAJLPsf","executionInfo":{"status":"ok","timestamp":1721384698355,"user_tz":-60,"elapsed":1089,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["# output directory name\n","output_dir = 'model_output/biLSTM'\n","\n","# training details\n","epochs = 6\n","batch_size = 128\n","\n","# LSTM layer architecture:\n","n_lstm = 256\n","drop_lstm = 0.2"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTjGCkTHMzDh"},"source":["Build the model"]},{"cell_type":"code","metadata":{"id":"UwYwMS3DLQGL","executionInfo":{"status":"ok","timestamp":1721384703883,"user_tz":-60,"elapsed":2509,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["model = Sequential()\n","model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n","model.add(SpatialDropout1D(drop_embed))\n","model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n","# add in the Bidirectional wrapper\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfVyFsnCLQOF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f9bb98a0-b71e-4900-f133-8e5e509e8aca","executionInfo":{"status":"ok","timestamp":1721384703883,"user_tz":-60,"elapsed":17,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 200, 64)           640000    \n","                                                                 \n"," spatial_dropout1d (Spatial  (None, 200, 64)           0         \n"," Dropout1D)                                                      \n","                                                                 \n"," bidirectional (Bidirection  (None, 512)               657408    \n"," al)                                                             \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1297921 (4.95 MB)\n","Trainable params: 1297921 (4.95 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"C2XeTZfVNDyI"},"source":["we can see the number of parameters is larger - as we increase the number of elements in the sequence (200 words)\n","\n","\n","Compile the model"]},{"cell_type":"code","metadata":{"id":"PN-zdA5yLQJ3","executionInfo":{"status":"ok","timestamp":1721384709830,"user_tz":-60,"elapsed":463,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d_G2RDNLQCj","executionInfo":{"status":"ok","timestamp":1721384712717,"user_tz":-60,"elapsed":1,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udKWa6KgNHO7"},"source":["Train the model\n","\n","* use the GPU with RNNs espcially a bi-directional LSTM.  \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"eTFGtg_kLP7I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"496429e2-62bb-405c-a875-0ad3f0cb4fcd","executionInfo":{"status":"ok","timestamp":1721384856120,"user_tz":-60,"elapsed":141034,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint]);"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/6\n","196/196 [==============================] - 45s 189ms/step - loss: 0.6135 - accuracy: 0.6761 - val_loss: 0.3815 - val_accuracy: 0.8356\n","Epoch 2/6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["196/196 [==============================] - 25s 126ms/step - loss: 0.3243 - accuracy: 0.8675 - val_loss: 0.3140 - val_accuracy: 0.8694\n","Epoch 3/6\n","196/196 [==============================] - 20s 102ms/step - loss: 0.2324 - accuracy: 0.9109 - val_loss: 0.3135 - val_accuracy: 0.8664\n","Epoch 4/6\n","196/196 [==============================] - 19s 95ms/step - loss: 0.1778 - accuracy: 0.9358 - val_loss: 0.3399 - val_accuracy: 0.8645\n","Epoch 5/6\n","196/196 [==============================] - 16s 80ms/step - loss: 0.1538 - accuracy: 0.9443 - val_loss: 0.3581 - val_accuracy: 0.8661\n","Epoch 6/6\n","196/196 [==============================] - 17s 87ms/step - loss: 0.1373 - accuracy: 0.9507 - val_loss: 0.4861 - val_accuracy: 0.8504\n"]}]},{"cell_type":"markdown","metadata":{"id":"ehHYWzf2NMEz"},"source":["Evaluate the epoch with highest accuracy / lowest loss"]},{"cell_type":"code","metadata":{"id":"KiBwaxhELPwD","executionInfo":{"status":"ok","timestamp":1721384864050,"user_tz":-60,"elapsed":413,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["# insert the relevant epoch\n","\n","model.load_weights(output_dir+\"/weights.03.hdf5\") # zero-indexed"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_HH6X9nLPju","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5faf4ab0-7e3b-44f1-8c74-9fa93cd26954","executionInfo":{"status":"ok","timestamp":1721384901703,"user_tz":-60,"elapsed":12203,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["y_hat = model.predict(x_valid)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 9s 9ms/step\n"]}]},{"cell_type":"code","metadata":{"id":"WEci5kJuLmNt"},"source":["plt.hist(y_hat)\n","_ = plt.axvline(x=0.5, color='orange')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLLRglR4LoqK","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"9587d6f1-89cc-4520-ff76-3100f356293e","executionInfo":{"status":"error","timestamp":1721384865980,"user_tz":-60,"elapsed":7,"user":{"displayName":"Francesca","userId":"10202045785671024504"}}},"source":["\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'y_hat' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-553d09d667a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"{:0.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'y_hat' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"tqP8WLhnOQoR"},"source":["This is the best RNN, but the CNN still has best ROC performance.\n","\n","Why not go for the CNN?  \n","\n","The CNN only considers three word features - so in a larger data set, the LSTM would pick up far more nuance (using a 200 word sequence)"]}]}